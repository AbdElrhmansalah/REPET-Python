{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook shows some examples for the different functions of the Python module `repet`.\n",
    "\n",
    "Functions:\n",
    "- [`original`](#original) - Compute the original REPET.\n",
    "- [`extended`](#extended) - Compute REPET extended.\n",
    "- [`adaptive`](#adaptive) - Compute the adaptive REPET.\n",
    "- [`sim`](#sim) - Compute REPET-SIM.\n",
    "- [`simonline`](#simonline) - Compute the online REPET-SIM.\n",
    "\n",
    "Other:\n",
    "- `wavread` - Read a WAVE file (using SciPy).\n",
    "- `wavwrite` - Write a WAVE file (using SciPy).\n",
    "- `sigplot` - Plot a signal in seconds.\n",
    "- `specshow` - Display a spectrogram in dB, seconds, and Hz.\n",
    "\n",
    "\n",
    "Author:\n",
    "- Zafar Rafii\n",
    "- zafarrafii@gmail.com\n",
    "- http://zafarrafii.com\n",
    "- https://github.com/zafarrafii\n",
    "- https://www.linkedin.com/in/zafarrafii/\n",
    "- 12/15/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"original\"></a>original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the original REPET.\n",
    "\n",
    "```\n",
    "background_signal = repet.original(audio_signal, sampling_frequency)\n",
    "\n",
    "Inputs:\n",
    "    audio_signal: audio signal (number_samples, number_channels)\n",
    "    sampling_frequency: sampling frequency in Hz\n",
    "Output:\n",
    "    background_signal: background signal (number_samples, number_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimate the background and foreground signals, and display their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import the modules\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import zaf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the audio signal (normalized) with its sampling frequency in Hz\n",
    "audio_signal, sampling_frequency = zaf.wavread(\"audio_file.wav\")\n",
    "\n",
    "# Estimate the background signal and derive the foreground signal\n",
    "background_signal = repet.original(audio_signal, sampling_frequency)\n",
    "foreground_signal = audio_signal-background_signal\n",
    "\n",
    "# Write the background and foreground signals\n",
    "zaf.wavwrite(sampling_frequency, background_signal, \"background_signal.wav\")\n",
    "zaf.wavwrite(sampling_frequency, foreground_signal, \"foreground_signal.wav\")\n",
    "\n",
    "# # Compute the audio, background, and foreground spectrograms\n",
    "# window_length = repet.windowlength(sample_rate)\n",
    "# window_function = repet.windowfunction(window_length)\n",
    "# step_length = repet.steplength(window_length)\n",
    "# audio_spectrogram = abs(repet._stft(np.mean(audio_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "# background_spectrogram = abs(repet._stft(np.mean(background_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "# foreground_spectrogram = abs(repet._stft(np.mean(foreground_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "\n",
    "# # Display the audio, background, and foreground spectrograms (up to 5kHz)\n",
    "# plt.rc('font', size=30)\n",
    "# plt.subplot(3, 1, 1)\n",
    "# plt.imshow(20*np.log10(audio_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "# plt.title('Audio Spectrogram (dB)')\n",
    "# plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "#            np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "#            np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "# plt.ylabel('Frequency (kHz)')\n",
    "# plt.subplot(3, 1, 2)\n",
    "# plt.imshow(20*np.log10(background_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "# plt.title('Background Spectrogram (dB)')\n",
    "# plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "#            np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "#            np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "# plt.ylabel('Frequency (kHz)')\n",
    "# plt.subplot(3, 1, 3)\n",
    "# plt.imshow(20*np.log10(foreground_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "# plt.title('Foreground Spectrogram (dB)')\n",
    "# plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "#            np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "#            np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "# plt.ylabel('Frequency (kHz)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"extended\"></a>extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute REPET extended.\n",
    "\n",
    "```\n",
    "background_signal = repet.extended(audio_signal, sampling_frequency)\n",
    "\n",
    "Inputs:\n",
    "    audio_signal: audio signal (number_samples, number_channels)\n",
    "    sampling_frequency: sampling frequency in Hz\n",
    "Output:\n",
    "    background_signal: background signal (number_samples, number_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimate the background and foreground signals, and display their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "import repet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Audio signal (normalized) and sample rate in Hz\n",
    "sample_rate, audio_signal = scipy.io.wavfile.read('audio_file.wav')\n",
    "audio_signal = audio_signal / (2.0**(audio_signal.itemsize*8-1))\n",
    "\n",
    "# Estimate the background signal and infer the foreground signal\n",
    "background_signal = repet.extended(audio_signal, sample_rate);\n",
    "foreground_signal = audio_signal-background_signal;\n",
    "\n",
    "# Write the background and foreground signals (un-normalized)\n",
    "scipy.io.wavfile.write('background_signal.wav', sample_rate, background_signal)\n",
    "scipy.io.wavfile.write('foreground_signal.wav', sample_rate, foreground_signal)\n",
    "\n",
    "# Compute the audio, background, and foreground spectrograms\n",
    "window_length = repet.windowlength(sample_rate)\n",
    "window_function = repet.windowfunction(window_length)\n",
    "step_length = repet.steplength(window_length)\n",
    "audio_spectrogram = abs(repet._stft(np.mean(audio_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "background_spectrogram = abs(repet._stft(np.mean(background_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "foreground_spectrogram = abs(repet._stft(np.mean(foreground_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "\n",
    "# Display the audio, background, and foreground spectrograms (up to 5kHz)\n",
    "plt.rc('font', size=30)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(20*np.log10(audio_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Audio Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(20*np.log10(background_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Background Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(20*np.log10(foreground_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Foreground Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"adaptive\"></a>adaptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the adaptive REPET.\n",
    "\n",
    "```\n",
    "background_signal = repet.adaptive(audio_signal, sampling_frequency)\n",
    "\n",
    "Inputs:\n",
    "    audio_signal: audio signal (number_samples, number_channels)\n",
    "    sampling_frequency: sampling frequency in Hz\n",
    "Output:\n",
    "    background_signal: background signal (number_samples, number_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimate the background and foreground signals, and display their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "import repet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Audio signal (normalized) and sample rate in Hz\n",
    "sample_rate, audio_signal = scipy.io.wavfile.read('audio_file.wav')\n",
    "audio_signal = audio_signal / (2.0**(audio_signal.itemsize*8-1))\n",
    "\n",
    "# Estimate the background signal and infer the foreground signal\n",
    "background_signal = repet.adaptive(audio_signal, sample_rate);\n",
    "foreground_signal = audio_signal-background_signal;\n",
    "\n",
    "# Write the background and foreground signals (un-normalized)\n",
    "scipy.io.wavfile.write('background_signal.wav', sample_rate, background_signal)\n",
    "scipy.io.wavfile.write('foreground_signal.wav', sample_rate, foreground_signal)\n",
    "\n",
    "# Compute the audio, background, and foreground spectrograms\n",
    "window_length = repet.windowlength(sample_rate)\n",
    "window_function = repet.windowfunction(window_length)\n",
    "step_length = repet.steplength(window_length)\n",
    "audio_spectrogram = abs(repet._stft(np.mean(audio_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "background_spectrogram = abs(repet._stft(np.mean(background_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "foreground_spectrogram = abs(repet._stft(np.mean(foreground_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "\n",
    "# Display the audio, background, and foreground spectrograms (up to 5kHz)\n",
    "plt.rc('font', size=30)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(20*np.log10(audio_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Audio Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(20*np.log10(background_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Background Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(20*np.log10(foreground_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Foreground Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"sim\"></a>sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute REPET-SIM.\n",
    "\n",
    "```\n",
    "background_signal = repet.sim(audio_signal, sampling_frequency)\n",
    "\n",
    "Inputs:\n",
    "    audio_signal: audio signal (number_samples, number_channels)\n",
    "    sampling_frequency: sampling frequency in Hz\n",
    "Output:\n",
    "    background_signal: background signal (number_samples, number_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimate the background and foreground signals, and display their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "import repet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Audio signal (normalized) and sample rate in Hz\n",
    "sample_rate, audio_signal = scipy.io.wavfile.read('audio_file.wav')\n",
    "audio_signal = audio_signal / (2.0**(audio_signal.itemsize*8-1))\n",
    "\n",
    "# Estimate the background signal and infer the foreground signal\n",
    "background_signal = repet.sim(audio_signal, sample_rate);\n",
    "foreground_signal = audio_signal-background_signal;\n",
    "\n",
    "# Write the background and foreground signals (un-normalized)\n",
    "scipy.io.wavfile.write('background_signal.wav', sample_rate, background_signal)\n",
    "scipy.io.wavfile.write('foreground_signal.wav', sample_rate, foreground_signal)\n",
    "\n",
    "# Compute the audio, background, and foreground spectrograms\n",
    "window_length = repet.windowlength(sample_rate)\n",
    "window_function = repet.windowfunction(window_length)\n",
    "step_length = repet.steplength(window_length)\n",
    "audio_spectrogram = abs(repet._stft(np.mean(audio_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "background_spectrogram = abs(repet._stft(np.mean(background_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "foreground_spectrogram = abs(repet._stft(np.mean(foreground_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "\n",
    "# Display the audio, background, and foreground spectrograms (up to 5kHz)\n",
    "plt.rc('font', size=30)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(20*np.log10(audio_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Audio Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(20*np.log10(background_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Background Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(20*np.log10(foreground_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Foreground Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"simonline\"></a>simonline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the online REPET-SIM.\n",
    "\n",
    "```\n",
    "background_signal = repet.simonline(audio_signal, sampling_frequency)\n",
    "\n",
    "Inputs:\n",
    "    audio_signal: audio signal (number_samples, number_channels)\n",
    "    sampling_frequency: sampling frequency in Hz\n",
    "Output:\n",
    "    background_signal: background signal (number_samples, number_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Estimate the background and foreground signals, and display their spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "import repet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Audio signal (normalized) and sample rate in Hz\n",
    "sample_rate, audio_signal = scipy.io.wavfile.read('audio_file.wav')\n",
    "audio_signal = audio_signal / (2.0**(audio_signal.itemsize*8-1))\n",
    "\n",
    "# Estimate the background signal and infer the foreground signal\n",
    "background_signal = repet.simonline(audio_signal, sample_rate);\n",
    "foreground_signal = audio_signal-background_signal;\n",
    "\n",
    "# Write the background and foreground signals (un-normalized)\n",
    "scipy.io.wavfile.write('background_signal.wav', sample_rate, background_signal)\n",
    "scipy.io.wavfile.write('foreground_signal.wav', sample_rate, foreground_signal)\n",
    "\n",
    "# Compute the audio, background, and foreground spectrograms\n",
    "window_length = repet.windowlength(sample_rate)\n",
    "window_function = repet.windowfunction(window_length)\n",
    "step_length = repet.steplength(window_length)\n",
    "audio_spectrogram = abs(repet._stft(np.mean(audio_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "background_spectrogram = abs(repet._stft(np.mean(background_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "foreground_spectrogram = abs(repet._stft(np.mean(foreground_signal, axis=1), window_function, step_length)[0:int(window_length/2)+1, :])\n",
    "\n",
    "# Display the audio, background, and foreground spectrograms (up to 5kHz)\n",
    "plt.rc('font', size=30)\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(20*np.log10(audio_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Audio Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(20*np.log10(background_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Background Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(20*np.log10(foreground_spectrogram[1:int(window_length/8), :]), aspect='auto', cmap='jet', origin='lower')\n",
    "plt.title('Foreground Spectrogram (dB)')\n",
    "plt.xticks(np.round(np.arange(1, np.floor(len(audio_signal)/sample_rate)+1)*sample_rate/step_length),\n",
    "        np.arange(1, int(np.floor(len(audio_signal)/sample_rate))+1))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.round(np.arange(1e3, int(sample_rate/8)+1, 1e3)/sample_rate*window_length),\n",
    "        np.arange(1, int(sample_rate/8*1e3)+1))\n",
    "plt.ylabel('Frequency (kHz)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
